# Adaptive Dynamic Programming

摘要：自适应动态规划(Adaptive/Approximate Dynamic Programming，ADP)是最优控制领域新兴起的一种近似最优方法，它在人工智能领域、强化学习、人工神经网络、模糊系统、演化计算等方面蓬勃发展，为求解非线性系统优化问题提供了很多解决思路和具体技术方法，是当前国际最优化领域的研究热点。本文将按照自适应动态规划的研究背景意义、国内外研究现状、理论发展及应用四个方面对其进行介绍及总结。

关键词：自适应动态规划，非线性系统，稳定性

**1 ADP的研究背景及意义**
动态运动、动态系统在自然界中普遍存在，对我们来说，要认识、理解并改善一个系统，对动态系统稳定性的研究必不可少。本世纪50∼60年代, 在空间技术发展和数字计算机实用化的推动下, 动态系统的优化理论得到了迅速的发展，形成了一个重要的学科分支：最优控制。它在空间技术、系统工程、经济管理与决策、人口控制、多级工艺设备的优化等许多领域都有越来越广泛的应用。1
20世纪50年代初美国数学家Bellman等人在研究多阶段决策过程(multistep decision process)的优化问题时，提出了著名的最优化原理(principle of optimality)，即把多阶段过程转化为一系列单阶段问题，利用各阶段之间的关系，逐个求解，创立了解决这类过程优化问题的新方法——动态规划(Dynamic Programming，DP)。动态规划，从本质上讲是一种非线性规划方法，其核心是贝尔曼最优性原理。这个原理可以归结为一个基本递推公式，从而使决策过程连续递推，并将一个多步（级）决策问题化简为多个一步（级）决策问题，从终端开始到始端逆向递推，从而简化了求解过程。自动态规划问世以来，其在经济管理、生产调度、工程技术和最优控制等方面得到了广泛的应用。例如最短路线、库存管理、资源分配、设备更新、排序、装载等问题，用动态规划方法比用其它方法求解更为方便。但是由于动态规划过程中其计算量和存储量会随着状态和控制的维数的增加而急剧增长，从而产生我们所说的“维数灾难”，再加上在实际应用中通常无法得到精确的数学解析表达式，故其应用范围受到了很大限制。
为克服这些缺点1977年，美国学者Paul J. Werbos首次提出了自适应动态规划（ADP）。ADP是一种新的非线性优化方法。模拟人通过环境反馈进行学习的思路，它融合了强化学习(Reinforcement Learning，RL)和动态规划的思想，被认为是一种非常接近人脑智能的方法，该方法有效地解决了动态规划“维数灾”的难题。
从ADP的研究表明，它具有其他非线性控制方法所没有的优势，如在处理“维数灾难”方面，展现了良好的应用效果和前景。而且，ADP对非线性系统的稳定性、收敛性、最优性等的处理也具有重要的作用，同时，在工业生产中，ADP也具有较好的应用价值和发展前景。因此，ADP具有很好的理论意义和实践意义。

**2 ADP国内外研究现状**
ADP方法自提出以来，吸引了控制领域的极大关注和重视并迅速发展，并在国内外涌现出许多研究成果。
1992年，Werbos提出了ADP基本结构中的三个模块:评判模块、模型模块以及执行模块，并且采用神经网络模型来近似每个模块，从而实现了ADP算法，同时还将ADP算法分为两种，即启发式动态规划(HDP)和双启发式动态规划(DHP)。
2007年，Powell WB在其著作中详细阐述了ADP如何解决维数灾的问题并给出了ADP未来的改进和发展方向。Hanselmann T等人研究了连续时间系统的自适应动态规划方法及其应用。
2008年，Al-Tamimi A，Lewis F L，Abu-Khalaf M等人运用ADP方法求解了一般离散时间非线性系统的HUB方程并对迭代ADP算法的收敛性进行了严格的数学证明，这一成果为迭代ADP算法在离散非线性系统控制中的应用提供了理论基础。Lu C，Si J，Xie X.将启发式动态规划算法(HDP)应用到电力系统中的阻尼震荡问题中，并取得了理想的控制效果。
2009年，Wang F Y, Zhang H, Liu D等学者对近几年ADP的研究成果进行了详细的综述，包括ADP的结构、算法的改进和发展、算法收敛性和稳定性分析以及ADP的应用。Lendaris G G将ADP应用于经验系统的辨识与控制中。
2010年，WEI Q L, Zhang H G LIUDR等学者运用ADP算法迭代得到离散时滞非线性系统的最优控制并采用BP神经网络来实现ADP算法得到了近似最优控制。Song R, Zhang H, Luo Y将迭代HDP方法应用到离散时滞非线性系统中，通过定义适当的性能指标函数，有效解决了执行器带饱和最优控制问题。
2011年，Wang F Y, Jin N, Liu D等人通过引入误差限 ，解决了有限时间城下的离散非线性系统近似最优控制问题，并对有限时间ADP算法的收敛性进行了分析。在有限时间ADP算法提出后，受到了ADP研究领域专家的重视，是近年来ADP领域一个重要的研究成果。Wang D, Liu D, Wei Q用有限时间ADP算法解决了离散时间非线性系统最优跟踪控制问题。
2012年，Boaro M，Fuselli D, De Angelis F等学者采用自适应动态规划方法对可再生能源及电池管理系统进行了控制。林小峰等学者对系统进行变化，重新定义了性能指标函数，引入合适的泛函来解决了控制带饱和问题，并通过迭代ADP算法解决了无限时间下的控制带时滞且饱和离散非线性系统最优控制。Lin X, Huang Y, Cao N等将有限时间ADP算法成功应用到执行器带饱和的离散非线性系统，得到了近似最优控制并保证了控制输出在饱和界范围内。
2013年，林小峰等学者对ADP算法的原理、结构和方法进行了介绍和总结，详细对ADP算法的BP神经网络实现方法及训练方法进行了公式推导，最后将ADP应用到工业系统，其相关成果《基于自适应动态规划的智能优化控制》是国内第一本全面介绍ADP方法和应用的著作。乔俊飞、薄迎春、韩广等学者研究了基于回声状态网络(ESN)的DHP算法。2
综上所述，作为一种新型的优化控制算，ADP方法已在离散及连续时间系统最优控制领域取得了丰富的理论及应用成果。然而，目前绝大部分成果都是考虑无限时间范围的最优控制问题，而实际系统需要在有限时问内控制到稳定并达到最优。有限时间ADP方法是未来ADP研究领域的一个重要的研究方向和研究难点。

**3 ADP的发展**
3.1 ADP理论的发展
ADP是融合了强化学习和动态规划（DP）思想的方法，其核心——贝尔曼最优性原理的适用范围非常广泛，从离散系统到连续系统，从线性系统到非线性系统，从确定系统到随机系统等均有较好的适用性。下面分别就离散和连续两种情况对 DP 方法的基本原理进行说明。对于离散非线性系统，假设一个系统的动态方程为
(1)
其中， 为系统的状态向量， 为控制输入向量，系统相应的代价函数 (或性能指标函数)
(2)
其中，给定初始状态 ， 是效用函数， 为折扣因子且满足0< <1。控制目标就是求解容许决策 (或控制) 序列 ，使得代价函数 (2)最小。
根据贝尔曼最优性原理，自第 时刻任意状态的最小代价包括两部分，其中一部分是第 时刻内所需最小代价，另一部分是从第 时刻开始到 穷的最小代价累加和，即
(3)
相应的k时刻的控制策略 也达到最优，表示为
(4)
接下来，考虑连续非线性 (时变) 动态 (确定) 系统的最优控制问题。考察如下的连续时间系统：
(5)
其中， 为任意连续函数. 求容许控制策略 使得代价函数 (或性能指标函数)
(6)
最小。 我们可以通过离散化的方法将连续问题转换为离散问题，然后通过离散动态规划方法求出最优控制，当离散化时间间隔趋于零时，两者必趋于一致，通过应用贝尔曼最优性原理，可以得到 DP 的连续形式为

可以看出，上式是 以 为自变量的一阶非线性偏微分方程，在数学上称其为哈密顿—雅可比—贝尔曼(Hamilton-Jacobi-Bellman, HJB)方程。1
如果系统是线性的且代价函数是状态和控制输入的二次型形式，那么其最优控制策略是状态反馈的形式，可以通过求解标准的黎卡提方程得到，如果系统是非线性系统或者代价函数不是状态和控制输入的二次型形式，那么就需要通过求解HJB方程进而获得最优控制策略。然而，HJB方程这种偏微分方程的求解是一件非常困难的事情.而且，随着x和u维数的增加，DP方法的计算量和存储量有着惊人的增长，造成我们平常所说的“维数灾”问题。为了解决这些问题，Werbos首先提出了自适应动态规划 (Adaptive dynamic programming, ADP) 方法的框架，其主要思想是利用一个函数近似结构 (例如神经网络、模糊模型、多项式等) 来估计代价函数，用于按时间正向求解DP 问题。

**最优性原理**（Bellman,1954）
多级决策过程的最优策略具有如下性质：不论初始状态和初始决策如何，其余的决策对于由初始决策所形成的状态来说，必定也是一个最优策略。

**例子**
动态规划求图中a点到h点的最短路径。
<center>
<img src="Adaptive Dynamic Programming/微信截图_20230829154000.png"></img>
</center>
$J_{ah}$表示从a点到h点的代价，$J_{ah}^*$表示从a点到h点的最小代价，$\phi(a)=b$表示在a点的最优决策是去b点。

从g点开始进行后向求解。

g：g只有一条到h的路径，$J_{gh}^*=2$，则$\phi(g)=h$

f：f只有一条到g的路径，$J_{fh}^*=J_{fg}+J_{gh}^*=5$，则$\phi(f)=g$

e：e有两条路径,选择到f或者到h，$J_{eh}^*=min\{J_{ef}+J_{fh}^*,J_{eh}\}=min\{2+5,8\}=7$，则$\phi(e)=f$

d：d只有一条到e的路径,$J_{dh}^*=J_{de}+J_{eh}^*=10$，则$\phi(d)=e$

c：c有两条路径,选择到d或者到f，$J_{ch}^*=min\{J_{cd}+J_{dh}^*,J_{cf}+J_{fh}^*\}=min\{5+10,3+5\}=8$，则$\phi(c)=f$

b：b只有一条到c的路径,$J_{bh}^*=J_{bc}+J_{ch}^*=17$，则$\phi(b)=c$

a：a有两条路径,选择到b或者到d，$J_{ah}^*=min\{J_{ab}+J_{bh}^*,J_{ad}+J_{dh}^*\}=min\{5+17,8+10\}=18$，则$\phi(a)=d$

现在已知$\phi(a)=d$，$\phi(d)=e$，$\phi(e)=f$，$\phi(f)=g$，$\phi(g)=h$则知晓了最优路径。

## 最优控制的离散化

时间：

考虑一个从$t_0$到$t_f$时刻的时间段

$$
t \in\left[t_0, t_f\right]
$$

将其离散化成$N$个时间段

$$
\Delta t=\left(t_f-t_0\right) / N
$$

每个时间段为

$$
\left[t_0+k \Delta t, t_0+(k+1) \Delta t\right) , k=0,1, \ldots, N-1
$$

状态方程：

$x(t)$是$t$时刻系统的状态，$u(t)$是$t$时刻系统的输入控制量

系统的状态的导数是关于$x(t),u(t),t$的函数

$$
\dot{x}(t)=\frac{dx(t)}{dt}=f(x(t), u(t), t), x\left(t_0\right)=x_0
$$

对$k \Delta t+\Delta t$时刻取微分有

$$
x(k \Delta t+\Delta t) \approx x(k \Delta t)+f(x(k \Delta t), u(k \Delta t), k \Delta t) \Delta t
$$

则

$$
x(k+1)=f_D(x(k), u(k), k)
$$

性能指标：

性能指标中$h\left(x\left(t_f\right), t_f\right)$是终止时刻$t_f$系统状态与目标状态的评价指标函数，$g(x(t), u(t), t)$是过程中每一步的评价指标函数，$\int_{t_0}^{t_f} g(x(t), u(t), t) d t$是过程中每一步的影响累计形成的评价指标函数

$$
J=h\left(x\left(t_f\right), t_f\right)+\int_{t_0}^{t_f} g(x(t), u(t), t) d t
$$

离散化后得到

$$
\begin{aligned}
J & =h\left(x\left(t_f\right), t_f\right)+\sum_{k=0}^{N-1} \int_{t_0+k \Delta t}^{t_0+(k+1) \Delta t} g(x(t), u(t), t) d t \\
& \approx h\left(x\left(t_f\right), t_f\right)+\sum_{k=0}^{N-1} g\left(x\left(t_0+k \Delta t\right), u\left(t_0+k \Delta t\right), k \Delta t\right) \Delta t
\end{aligned}
$$

记为

$$
J=h_D(x(N), N)+\sum_{k=0}^{N-1} g_D(x(k), u(k), k)
$$

## Bellman方程

1 状态方程

$$
\dot{x}(t)=\frac{dx(t)}{dt}=f(x(t), u(t), t), x\left(t_0\right)=x_0
$$

2 容许控制

$$
u \in U
$$

3 最小化性能指标

$$
J\left(u\right)=h_D(x(N), N)+\sum_{k=k_0}^{N-1} g_D(x(k), u(k), k)
$$

考虑包含初值和初始时段的更广泛的性能指标

$$
J\left(u , x_0, k_0\right)=h_D(x(N), N)+\sum_{k=k_0}^{N-1} g_D(x(k), u(k), k)
$$

最优控制下的性能指标记为“值函数”

$$
V\left(x_0, k_0\right)=\min _{u \in U} J\left(u , x_0, k_0\right)
$$

根据最优性原理，如下Bellman方程是最优控制的充要条件

$$
V(x(k), k)=\min _{u(k) \in U}\left\{g_D(x(k), u(k), k)+V(x(k+1), k+1)\right\} ,k=0,1, \ldots, N-1
$$

$$
V(x(N), N)=h_D(x(N), N)
$$

## ADP 的模型框架
启发式动态规划(Heuristic Dynamic Programming，HDP)
双启发式动态规划(Dual Heuristic Programming，DHP)
全局双启发式动态规划(Globalized Dual heuristic Programming，GDHP)
将模型网络和评价网络合并形成的 ADHDP，ADDHP， ADGDHP 三种动作依赖(Action-Dependent)的 ADP 模型

在 DHP，HDP，GDHP 中，有评价网络(Critic Network)、模型网络(Model Network)和执行网络(Action Network)。在 ADHDP，ADDHP，ADGDHP 仅有执行网络(Action Network)和评价网络(Critic Network)。